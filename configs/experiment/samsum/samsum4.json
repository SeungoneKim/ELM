{
    "do_train": true,
    "do_eval": false,
    "do_test": false,
    "warmup_steps": 0,
    "save_steps": 1000,
    "model_name_or_path": "google/t5-xl-lm-adapt",
    "tokenizer_name": "google/t5-xl-lm-adapt",
    "save_total_limit": 1,
    "per_device_train_batch_size": 2,
    "per_device_eval_batch_size": 2,
    "load_best_model_at_end": false,
    "metric_for_best_model": "rougeL",
    "greater_is_better": false,
    "evaluation_strategy": "epoch",
    "non_linearity": "gelu_new",
    "max_source_length": 512,
    "learning_rate": 1e-4,
    "output_dir": "expert_weights/samsum/To sum up this dialog",
    "split_validation_test": true,
    "task_name": ["samsum"],
    "adapters_cur_training_task":"samsum",
    "dataset_config_name": ["none"],
    "eval_dataset_name": ["samsum",
    "hellaswag","hellaswag","hellaswag","hellaswag","hellaswag","hellaswag","hellaswag",
    "story_cloze","story_cloze","story_cloze","story_cloze","story_cloze",
    "anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1","anli_r1",
    "anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2","anli_r2",
    "anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3","anli_r3",
    "super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa","super_glue_copa",
    "super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb","super_glue_cb",
    "super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte","super_glue_rte",
    "super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed","super_glue_wsc.fixed",
    "super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic","super_glue_wic",
    "winogrande","winogrande","winogrande","winogrande","winogrande","winogrande"
    ],
    "eval_dataset_config_name": ["none",
    "none","none","none","none","none","none","none",
    "none","none","none","none","none",
    "dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1","dev_r1",
    "dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2","dev_r2",
    "dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3","dev_r3",
    "copa","copa","copa","copa","copa","copa","copa","copa","copa","copa","copa","copa",
    "cb","cb","cb","cb","cb","cb","cb","cb","cb","cb","cb","cb","cb","cb","cb",
    "rte","rte","rte","rte","rte","rte","rte","rte","rte","rte",
    "wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed","wsc.fixed",
    "wic","wic","wic","wic","wic","wic","wic","wic","wic","wic",
    "winogrande_xl","winogrande_xl","winogrande_xl","winogrande_xl","winogrande_xl","winogrande_xl"
    ],
    "eval_prompts": [
        "To sum up this dialog",
        "complete_first_then","Randomized prompts template","Appropriate continuation - Yes or No","Predict ending with hint","Reversed appropriate continuation - Yes or No","how_ends","if_begins_how_continues",
        "Answer Given options","Choose Story Ending","Movie What Happens Next","Story Continuation and Options","Novel Correct Ending",
        "MNLI crowdsource","should assume","does it follow that","GPT-3 style","based on the previous passage","justified in saying","take the following as truth","must be true","can we infer","guaranteed/possible/impossible","always/sometimes/never","does this imply","consider always/sometimes/never","claim true/false/inconclusive","guaranteed true",
        "MNLI crowdsource","should assume","does it follow that","GPT-3 style","based on the previous passage","justified in saying","take the following as truth","must be true","can we infer","guaranteed/possible/impossible","always/sometimes/never","does this imply","consider always/sometimes/never","claim true/false/inconclusive","guaranteed true",
        "MNLI crowdsource","should assume","does it follow that","GPT-3 style","based on the previous passage","justified in saying","take the following as truth","must be true","can we infer","guaranteed/possible/impossible","always/sometimes/never","does this imply","consider always/sometimes/never","claim true/false/inconclusive","guaranteed true",
        "exercise","\u2026What could happen next, C1 or C2?","i_am_hesitating","plausible_alternatives","C1 or C2? premise, so/because\u2026","\u2026As a result, C1 or C2?","best_option","\u2026which may be caused by","more likely","cause_effect","\u2026why? C1 or C2","choose",
        "can we infer","based on the previous passage","claim true/false/inconclusive","does it follow that","justified in saying","always/sometimes/never","GPT-3 style","consider always/sometimes/never","guaranteed true","must be true","guaranteed/possible/impossible","does this imply","MNLI crowdsource","should assume","take the following as truth",
        "MNLI crowdsource","guaranteed true","can we infer","GPT-3 style","does this imply","should assume","does it follow that","based on the previous passage","justified in saying","must be true",
        "does the pronoun refer to","by p they mean","in other words","I think they mean","does p stand for","GPT-3 Style","replaced with","p is/are r","the pronoun refers to","Who or what is/are",
        "question-context-meaning-with-label","question-context-meaning","grammar_homework","affirmation_true_or_false","GPT-3-prompt","same_sense","question-context","GPT-3-prompt-with-label","polysemous","similar-sense",
        "does underscore refer to","stand for","underscore refer to","fill in the blank","True or False","Replace"
    ],
    "test_dataset_name": ["superglue_glue","superglue_glue"],
    "test_dataset_config_name": ["rte","copa"],
    "num_train_epochs": 5,
    "predict_with_generate": false,
    "add_layer_norm_before_adapter": false, 
    "add_layer_norm_after_adapter": false, 
    "adapter_config_name": "adapter",
    "train_task_adapters": true,
    "task_reduction_factor": 32,
    "unfreeze_lm_head": false,
    "unfreeze_layer_norms": true,
    "overwrite_output_dir": true,
    "max_train_samples": 10000,
    "max_val_samples": 300,
    "max_test_samples": 100,
    "train_prompts": ["To sum up this dialog"],
    "test_prompts": ["can we infer","best_option"]
    }